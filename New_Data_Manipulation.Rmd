---
title: "Data Manipulation"
author: "Irfan Emrah Kanat, Arianna Sammarchi"
date: "2023-02-01"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this document, I will try to walk you through some simple data manipulatione examples. As one might guess, data manipulation is sometimes more of an art, than science. Thus, what I can effectively teach you will be limited. We will learn some basic manipulations with dplyr package and vanilla R. dplyr provides a set of sensible functions to throw data around.

```{r, message=FALSE}
library(dplyr)
```

We will conduct our exercise on Worldbank GDP figures and continent information.

The GDP figures data is in GDP.csv. Let us read in the file.

```{r}
GDP<-read.csv("GDP.csv")
head(GDP)
```

As you can see, the data is in what we call the wide format. Each row is a country and observations over time are in columns.

Let us also get the second data set: Continents and country codes.

```{r}
Continents<-read.csv("continent.csv")
head(Continents)
```

## Combine Two Datasets

The most basic operation you can do with two datasets is to combine them. If you want to append new observations to an existing dataset, use rbind. If you want to append new variables to an existing dataset, use cbind. Note that the columns/rows need to be compatible in such combinations.

```{r}
# Append one dataset to another
# Append rows
rbind(Continents[1:3,] ,Continents[231:233,])
# Append columns
cbind(Continents[1:3,] ,Continents[231:233,])
```


If you want to combine two datasets based on the values of a common column however, you will need to do a merge. Merging is similar to a join operation in SQL if you are familiar with it. 

Below is the syntax for merge()

merge(x, y, by = intersect(names(x), names(y)),
      by.x = by, by.y = by, all = FALSE, all.x = all, all.y = all,
      sort = TRUE, suffixes = c(".x",".y"))


As you can see, a lot of the parameters are optional (have default values). Let us use merge to join Continents dataset to GDP dataset.

```{r}
cData <- merge(Continents, GDP)
head(cData)
```

I did not need to specify which column to merge on as by has a default value of intersect(names(x), names(y)). This means, if there are common column names between two datasets the two will be merged on common column names.

Let us go over some of the more commonly used parameters.

by, by.x, by.y: column name to merge on between quotation marks. If the two datasets have different names, use by.x and by.y to separately specify the column names.

```{r, eval=FALSE}
merge(Continents, GDP, by = "ISO2")
```

all, all.x, all.y: It determines what to do with rows that can not be matched in both datasets. From an SQL perspective, the all parameters specify the type of join operation. all.x = TRUE left join (keep rows from left table even if not matched), all.y = TRUE left join, and all = TRUE for an outer join. 

## Subset Rows Based on Column Values

If you want to select certain rows of output based on a column, this is what you do. When we wanted to filter certain observations in the first session we used indexing with logical operations before. 

Let us select observations in Oceania first.

First let us see how this is done in R:

```{r}
# displaying the first 6 columns to conserve space
# !is.na bit is required due to how R matches the == with NA's
cData[cData$Continent == "OC" & !is.na(cData$Continent),1:6] 
```

A better way is to subset the data (subset is part of the base package):

```{r}
subset(cData[,1:6], Continent == "OC")
```

With dplyr:

```{r}
filter(cData[,1:6], Continent == "OC")
```

You can also filter based on multiple columns. Let us say we are interested in countries in Oceania that are rich (GDP greater than 3rd quartile).

```{r}
cData[cData$Continent == "OC" & !is.na(cData$Continent) & cData$X2011 > 23000 & !is.na(cData$X2011),]
```

I believe you would agree that, it is not very convenient. Filter to the rescue.

```{r}
filter(cData, Continent == "OC" & X2011 > 23000)
```



## Selecting Certain Columns

Let us say we are interested only in the GDP figures and not in any of the country identifiers. We would want to select only certain columns.

Traditional R ways:

```{r}
# Limiting number of rows to 3 to conserve space
cData[1:3,4:13] # Indexing by column numbers
cData[1:3,-(1:3)] # Negative indexing
cData[1:3,grep("X", colnames(cData))] # Another way based on partial matching column name
```

subset can also handle this:

```{r}
subset(cData[1:3,], select = -c(ISO2, Continent, Country)) # Drop these columns
```

dplyr way:

```{r}
select(cData[1:3,], X2003:X2012) # All columns between X2003 and X2012
select(cData[1:3,], -(ISO2:Country))
```

## Aggregating based on Groups

Let us say we want to calculate the average GDP per continent in 2011 and the number of countries in each continent. 

R way:

```{r}
Cont1 <- aggregate(cData$X2011 ~ cData$Continent, FUN=function(x)mean(x, na.rm=T))
Cont1
Cont2 <- aggregate(cData$X2011 ~ cData$Continent, FUN=function(x) length(x))
Cont2
Cont <- merge(Cont1, Cont2, by='cData$Continent')
Cont
rm(Cont1, Cont2)
```

dplyr way:

```{r}
# Create grouped data
contiData <- group_by(cData, Continent)
contiData
# Create variables on the fly
summarise(contiData, count=n(), GDP2012 = mean(X2012, na.rm = T))
```



```

Save dataset for later use.

```{r}
write.csv(contiData, file="contiData.csv", row.names=F)
```


------

![Creative Commons 4](figures/cc.png) How I Learned to Stop Worrying and Love the R Console by [Irfan E Kanat](http://irfankanat.com) is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/). Based on a work at [http://github.com/iekanat/rworkshop](http://github.com/iekanat/rworkshop).